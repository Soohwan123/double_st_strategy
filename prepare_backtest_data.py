"""
Double SuperTrend Strategy - 2025ë…„ 6-11ì›” ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ë°”ì´ë‚¸ìŠ¤ì—ì„œ 2025ë…„ 6ì›”-11ì›” 5ë¶„ë´‰, 1ì‹œê°„ë´‰ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
2. SuperTrend(12,1), SuperTrend(12,3) ì§€í‘œ ê³„ì‚°
3. 5ë¶„ë´‰ê³¼ 1ì‹œê°„ë´‰ ë°ì´í„° ë³‘í•©
4. ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ìš© CSV ìƒì„±

ì‚¬ìš©ë²•:
    python prepare_backtest_data_2025.py
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime
import time
import os
from calculate_indicators import (
    calculate_indicators_5m,
    calculate_indicators_1h,
    prepare_final_columns
)

# ================================================================================
# CONFIG: ëª¨ë“  ì„¤ì • ê°’ (ììœ ë¡­ê²Œ ìˆ˜ì • ê°€ëŠ¥)
# ================================================================================

# ë‹¤ìš´ë¡œë“œ ê¸°ê°„ ì„¤ì •
START_DATE = '2020-01-01'  # ì‹œì‘ ë‚ ì§œ
END_DATE = '2025-11-05'    # ì¢…ë£Œ ë‚ ì§œ

# ì‹¬ë³¼ ì„¤ì •
SYMBOL = 'BTCUSDT'

# íƒ€ì„í”„ë ˆì„ ì„¤ì •
TIMEFRAMES = ['5m', '1h']  # 5ë¶„ë´‰, 1ì‹œê°„ë´‰

# ë””ë ‰í† ë¦¬ ì„¤ì •
OUTPUT_DIR = 'historical_data_2025/'       # ì›ì‹œ ë°ì´í„° ì €ì¥ ê²½ë¡œ
BACKTEST_DATA_DIR = 'backtest_data_2025/'  # ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥ ê²½ë¡œ

# íŒŒì¼ëª… ì„¤ì •
RAW_FILENAME_FORMAT = "{symbol}_{interval}_2025_raw.csv"           # ì›ì‹œ ë°ì´í„° íŒŒì¼ëª… í˜•ì‹
FINAL_FILENAME_FORMAT = "{symbol}_double_st_2025_01_01.csv"        # ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ íŒŒì¼ëª… í˜•ì‹

# API ì„¤ì •
API_LIMIT = 1500              # ë°”ì´ë‚¸ìŠ¤ API í•œ ë²ˆ ìš”ì²­ ì‹œ ìµœëŒ€ ìº”ë“¤ ìˆ˜
API_SLEEP = 0.1               # API ìš”ì²­ ê°„ê²© (ì´ˆ)
API_RETRY_SLEEP = 5           # API ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# ì§„í–‰ ìƒí™© ì¶œë ¥ ì„¤ì •
PROGRESS_UPDATE_INTERVAL = 15000  # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ê°„ê²© (ìº”ë“¤ ìˆ˜)

# ì¶œë ¥ ë©”ì‹œì§€ ì„¤ì •
TITLE = "Double SuperTrend Strategy - 2025ë…„ 1-11ì›” ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"
SECTION_DIVIDER = "=" * 80
DOWNLOAD_HEADER = "ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {symbol} {interval}"
DOWNLOAD_PERIOD = "   ê¸°ê°„: {start} ~ {end}"
PROGRESS_MSG = "   ì§„í–‰ ì¤‘... {date} ({count:,} candles)"
ERROR_MSG = "   âš ï¸ API Error: {error}"
RETRY_MSG = "   5ì´ˆ í›„ ì¬ì‹œë„..."
NO_DATA_MSG = "   âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ"
DOWNLOAD_SUCCESS = "   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {count:,} candles"
SAVE_SUCCESS = "   ğŸ’¾ ì €ì¥ ì™„ë£Œ: {path}"
MERGE_START = "ğŸ“Š íƒ€ì„í”„ë ˆì„ ë³‘í•© ì¤‘..."
MERGE_SUCCESS = "   âœ… ë³‘í•© ì™„ë£Œ: {count:,} rows"
INDICATOR_5M_MSG = "5ë¶„ë´‰ SuperTrend ì§€í‘œ ê³„ì‚°"
INDICATOR_1H_MSG = "1ì‹œê°„ë´‰ SuperTrend ì§€í‘œ ê³„ì‚°"
INDICATOR_SUCCESS = "   âœ… {interval} ì§€í‘œ ê³„ì‚° ì™„ë£Œ"
NAN_WARNING = "   âš ï¸ NaN ì œê±°: {count} rows (ì§€í‘œ ê³„ì‚° ì´ˆê¸° êµ¬ê°„)"
FINAL_SAVE_MSG = "   ğŸ’¾ ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥: {path}"
DATA_SIZE_MSG = "   ğŸ“Š ë°ì´í„° í¬ê¸°: {rows:,} rows x {cols} columns"
SUMMARY_TITLE = "ğŸ“‹ ìµœì¢… ë°ì´í„° ìš”ì•½"
SAMPLE_TITLE = "ğŸ” ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 5í–‰)"
COMPLETE_MSG = "âœ… 2025ë…„ 1-11ì›” ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!"

# ================================================================================
# 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
# ================================================================================

def download_binance_klines(symbol, interval, start_date, end_date):
    """ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼ ìº”ë“¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    base_url = 'https://fapi.binance.com/fapi/v1/klines'

    # ë‚ ì§œë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
    start_ms = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp() * 1000)
    end_ms = int(datetime.strptime(end_date, '%Y-%m-%d').timestamp() * 1000)

    all_klines = []
    current_start = start_ms

    print(f"\n{SECTION_DIVIDER}")
    print(DOWNLOAD_HEADER.format(symbol=symbol, interval=interval))
    print(DOWNLOAD_PERIOD.format(start=start_date, end=end_date))
    print(SECTION_DIVIDER)

    while current_start < end_ms:
        params = {
            'symbol': symbol,
            'interval': interval,
            'startTime': current_start,
            'endTime': end_ms,
            'limit': API_LIMIT
        }

        try:
            response = requests.get(base_url, params=params)
            response.raise_for_status()
            klines = response.json()

            if not klines:
                break

            all_klines.extend(klines)
            current_start = klines[-1][0] + 1

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if len(all_klines) % PROGRESS_UPDATE_INTERVAL == 0:
                current_date = datetime.fromtimestamp(klines[-1][0] / 1000).strftime('%Y-%m-%d')
                print(PROGRESS_MSG.format(date=current_date, count=len(all_klines)))

            time.sleep(API_SLEEP)  # API ì œí•œ ê³ ë ¤

        except requests.exceptions.RequestException as e:
            print(ERROR_MSG.format(error=e))
            print(RETRY_MSG)
            time.sleep(API_RETRY_SLEEP)
            continue

    if not all_klines:
        print(NO_DATA_MSG)
        return None

    # DataFrame ë³€í™˜
    df = pd.DataFrame(all_klines, columns=[
        'timestamp', 'Open', 'High', 'Low', 'Close', 'Volume',
        'Close_time', 'Quote_volume', 'Trades', 'Taker_buy_base',
        'Taker_buy_quote', 'Ignore'
    ])

    # íƒ€ì… ë³€í™˜
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
    df[numeric_cols] = df[numeric_cols].astype(float)

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']]

    print(DOWNLOAD_SUCCESS.format(count=len(df)))

    return df


# ================================================================================
# 2. ë°ì´í„° ì €ì¥ í•¨ìˆ˜
# ================================================================================

def save_data(df, symbol, interval, output_dir):
    """ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)

    filename = RAW_FILENAME_FORMAT.format(symbol=symbol, interval=interval)
    filepath = os.path.join(output_dir, filename)

    df.to_csv(filepath, index=False)
    print(SAVE_SUCCESS.format(path=filepath))

    return filepath


# ================================================================================
# 3. ë°ì´í„° ë³‘í•© í•¨ìˆ˜
# ================================================================================

def merge_timeframes(df_5m, df_1h):
    """
    5ë¶„ë´‰ê³¼ 1ì‹œê°„ë´‰ ë°ì´í„° ë³‘í•©
    1ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ 1ì‹œê°„ ì•ìœ¼ë¡œ shiftí•˜ì—¬ ë³‘í•©
    ì˜ˆ: 5ë¶„ë´‰ 19:00 ë°ì´í„° = 1ì‹œê°„ë´‰ 20:00 ë°ì´í„°ì™€ ë§¤ì¹­
    """
    print(f"\n{MERGE_START}")

    # 1ì‹œê°„ë´‰ ì»¬ëŸ¼ëª… ë³€ê²½
    df_1h_renamed = df_1h.copy()
    df_1h_renamed.columns = [col + '_1h' if col != 'timestamp' else col
                             for col in df_1h.columns]

    # 1ì‹œê°„ë´‰ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ 1ì‹œê°„ ë’¤ë¡œ ì´ë™ (ë°ì´í„°ëŠ” 1ì‹œê°„ ì•ì˜ ê²ƒì„ ì‚¬ìš©)
    # ì¦‰, ì›ë˜ 20:00 ë°ì´í„°ë¥¼ 19:00 ìœ„ì¹˜ë¡œ ì´ë™
    df_1h_renamed['timestamp'] = df_1h_renamed['timestamp'] - pd.Timedelta(hours=1)

    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    df_5m = df_5m.sort_values('timestamp')
    df_1h_renamed = df_1h_renamed.sort_values('timestamp')

    # 1ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ 5ë¶„ë´‰ì— ë§ì¶° ë³‘í•© (forward fill)
    # shiftëœ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    df_merged = pd.merge_asof(
        df_5m,
        df_1h_renamed,
        on='timestamp',
        direction='backward'  # ì´ì „ 1ì‹œê°„ë´‰ ë°ì´í„° ì‚¬ìš©
    )

    print(MERGE_SUCCESS.format(count=len(df_merged)))
    print(f"   ğŸ“Œ 1ì‹œê°„ë´‰ ë°ì´í„°ê°€ 1ì‹œê°„ ì•ìœ¼ë¡œ shiftë¨ (5ë¶„ë´‰ 19:00 = 1ì‹œê°„ë´‰ 20:00)")

    return df_merged


# ================================================================================
# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ================================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + SECTION_DIVIDER)
    print(f"ğŸš€ {TITLE}")
    print(SECTION_DIVIDER)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(BACKTEST_DATA_DIR, exist_ok=True)

    # 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    print("\n[STEP 1/5] ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

    data_files = {}
    for interval in TIMEFRAMES:
        df = download_binance_klines(SYMBOL, interval, START_DATE, END_DATE)
        if df is not None:
            filepath = save_data(df, SYMBOL, interval, OUTPUT_DIR)
            data_files[interval] = df
        else:
            print(f"   âŒ {interval} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return

    # 2. ì§€í‘œ ê³„ì‚° (5ë¶„ë´‰)
    print(f"\n[STEP 2/5] {INDICATOR_5M_MSG}")
    df_5m = data_files['5m'].copy()
    df_5m = calculate_indicators_5m(df_5m)
    print(INDICATOR_SUCCESS.format(interval='5ë¶„ë´‰'))

    # 3. ì§€í‘œ ê³„ì‚° (1ì‹œê°„ë´‰)
    print(f"\n[STEP 3/5] {INDICATOR_1H_MSG}")
    df_1h = data_files['1h'].copy()
    df_1h = calculate_indicators_1h(df_1h)
    print(INDICATOR_SUCCESS.format(interval='1ì‹œê°„ë´‰'))

    # 4. ë°ì´í„° ë³‘í•©
    print("\n[STEP 4/5] íƒ€ì„í”„ë ˆì„ ë³‘í•©")
    df_merged = merge_timeframes(df_5m, df_1h)

    # 5. ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬ ë° ì €ì¥
    print("\n[STEP 5/5] ìµœì¢… ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±")
    df_final = prepare_final_columns(df_merged)

    # NaN ì œê±° (ì´ˆê¸° êµ¬ê°„)
    initial_rows = len(df_final)
    df_final = df_final.dropna()
    dropped_rows = initial_rows - len(df_final)

    if dropped_rows > 0:
        print(NAN_WARNING.format(count=dropped_rows))

    # ìµœì¢… íŒŒì¼ ì €ì¥
    output_filename = FINAL_FILENAME_FORMAT.format(symbol=SYMBOL)
    output_path = os.path.join(BACKTEST_DATA_DIR, output_filename)
    df_final.to_csv(output_path, index=False)

    print(FINAL_SAVE_MSG.format(path=output_path))
    print(DATA_SIZE_MSG.format(rows=len(df_final), cols=len(df_final.columns)))

    # ë°ì´í„° ìš”ì•½ ì¶œë ¥
    print("\n" + SECTION_DIVIDER)
    print(SUMMARY_TITLE)
    print(SECTION_DIVIDER)
    print(f"ê¸°ê°„: {df_final['timestamp'].min()} ~ {df_final['timestamp'].max()}")
    print(f"í–‰ ìˆ˜: {len(df_final):,}")
    print(f"ì»¬ëŸ¼ ìˆ˜: {len(df_final.columns)}")
    print(f"\nì»¬ëŸ¼ ëª©ë¡:")
    for i, col in enumerate(df_final.columns, 1):
        print(f"  {i:2d}. {col}")

    # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print("\n" + SECTION_DIVIDER)
    print(SAMPLE_TITLE)
    print(SECTION_DIVIDER)
    print(df_final.head())

    print(f"\n{COMPLETE_MSG}")
    print(f"   íŒŒì¼: {output_path}")
    print(f"   ì´ì œ {START_DATE} ~ {END_DATE} ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()